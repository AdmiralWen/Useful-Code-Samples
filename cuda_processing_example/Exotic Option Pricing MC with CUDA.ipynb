{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exotic Option Pricing with GPU-Accelerated MonteCarlo Simulations\n",
    "Experiment for running large Monte-Carlo simulations for pricing an Asian Barrier Option. We will compare the runtimes of CPU-only runs as well as GPU-accelerated runs. For GPU acceleration, we will require a Nvidia Pascal or later GPU, along with the correct drivers installed. We'll also need the CuPY and numba libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports:\n",
    "import cupy\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import numba\n",
    "from numba import cuda\n",
    "from numba import njit\n",
    "from numba import prange\n",
    "#import cudf\n",
    "\n",
    "cupy.cuda.set_allocator(None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hardware specs:\n",
    "We'll be comparing CPU single-threaded, CPU multi-threaded, and GPU performance runtimes. So first let's take a look at the machine's hardware specs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU threads: 20\n"
     ]
    }
   ],
   "source": [
    "# CPU thread count:\n",
    "import multiprocessing\n",
    "n_cpus = multiprocessing.cpu_count()\n",
    "print('CPU threads:', n_cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n"
     ]
    }
   ],
   "source": [
    "# Verify GPU device is located:\n",
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters and run simulations\n",
    "\n",
    "The specific option being simulated here is an Asian Barrier Down-and-Out. Stock price will be simulated based on the widely used Geometric Brownian Motion framework.\n",
    "- Maturity (T): 1 year\n",
    "- Spot (S) : 120\n",
    "- Strike (K): 110\n",
    "- Barrier (B): 100\n",
    "- Volatility (sigma): 35.0 %\n",
    "- Risk Free Rate (r): 5.0 %\n",
    "- Stock Drift Rate (mu): 10.0 %\n",
    "\n",
    "The price of the option, after simulation paths have been generated, is simply the discounted expected payoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simulation parameters:\n",
    "N_PATHS = 8000000\n",
    "N_STEPS = 365\n",
    "\n",
    "T = 1.0\n",
    "K = 110.0\n",
    "B = 100.0\n",
    "S0 = 120.0\n",
    "sigma = 0.35\n",
    "mu = 0.1\n",
    "r = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use CuPy to generate Gaussian random numbers in the GPU and allocate an array to store the prices at maturity.\n",
    "randoms_gpu = cupy.random.normal(0, 1, N_PATHS * N_STEPS, dtype=cupy.float32)\n",
    "randoms_cpu = cupy.asnumpy(randoms_gpu)\n",
    "\n",
    "# Output array:\n",
    "output = np.zeros(N_PATHS, dtype=np.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Single Thread CPU\n",
    "The single thread CPU code for the simulation has two nested for-loops. The outer loop iterates each path (the possible paths that the underlying asset might take) while the inner loop computes the underlying asset price for that path by iterating through the 365 days of the path. Notice that for this pricing exercise we're limiting ourselves to daily price changes, rather than intra-day changes.\n",
    "\n",
    "Notice the `break` in the inner loop - this is due to the Down-and-Out barrier being breached, and hence the option being voided.\n",
    "\n",
    "To speed things up, we're using Numba's @jit decorator, hence the code compiles into machine code at runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single-threaded run. Using `fastmath` helps to improve runtime as it relaxes some floating point compute rigor requirements.\n",
    "@njit(fastmath=True)\n",
    "def cpu_barrier_option(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS):\n",
    "    tmp1 = mu*T/N_STEPS\n",
    "    tmp2 = math.exp(-r*T)\n",
    "    tmp3 = math.sqrt(T/N_STEPS)\n",
    "\n",
    "    for i in range(N_PATHS):\n",
    "        s_curr = S0\n",
    "        running_average = 0.0\n",
    "        for n in range(N_STEPS):\n",
    "            s_curr += tmp1 * s_curr + sigma*s_curr*tmp3*d_normals[i + n * N_PATHS]\n",
    "            running_average = running_average + 1.0/(n + 1.0) * (s_curr - running_average)\n",
    "            if running_average <= B:\n",
    "                break\n",
    "\n",
    "        payoff = running_average - K if running_average>K else 0\n",
    "        d_s[i] = tmp2 * payoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single-threaded CPU runtime: 11.732485294342041\n",
      "Simulated expected payoff: 18.703484\n"
     ]
    }
   ],
   "source": [
    "# Run Monte Carlo:\n",
    "t0 = time.time()\n",
    "cpu_barrier_option(output, np.float32(T), np.float32(K),\n",
    "                    np.float32(B), np.float32(S0),\n",
    "                    np.float32(sigma), np.float32(mu),\n",
    "                    np.float32(r), randoms_cpu, N_STEPS, N_PATHS)\n",
    "print('Single-threaded CPU runtime:', time.time() - t0)\n",
    "\n",
    "exp_payoff = output.mean()\n",
    "print('Simulated expected payoff:', exp_payoff)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multi-Thread CPU\n",
    "We can parallelize the outer loop (which are all independent) by calling the outer loop with `prange` instead of `range`. Also note the `parallel = True` adjustment in the decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-threaded run:\n",
    "@njit(fastmath=True, parallel=True)\n",
    "def cpu_multicore_barrier_option(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS):\n",
    "    tmp1 = mu*T/N_STEPS\n",
    "    tmp2 = math.exp(-r*T)\n",
    "    tmp3 = math.sqrt(T/N_STEPS)\n",
    "\n",
    "    for i in prange(N_PATHS):\n",
    "        s_curr = S0\n",
    "        running_average = 0.0\n",
    "        for n in range(N_STEPS):\n",
    "            s_curr += tmp1 * s_curr + sigma*s_curr*tmp3*d_normals[i + n * N_PATHS]\n",
    "            running_average = running_average + 1.0/(n + 1.0) * (s_curr - running_average)\n",
    "            if running_average <= B:\n",
    "                break\n",
    "\n",
    "        payoff = running_average - K if running_average>K else 0\n",
    "        d_s[i] = tmp2 * payoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-threaded CPU runtime: 1.009613275527954\n",
      "Simulated expected payoff: 18.703484\n"
     ]
    }
   ],
   "source": [
    "# Run Monte Carlo:\n",
    "t0 = time.time()\n",
    "cpu_multicore_barrier_option(output, np.float32(T), np.float32(K),\n",
    "                            np.float32(B), np.float32(S0),\n",
    "                            np.float32(sigma), np.float32(mu),\n",
    "                            np.float32(r), randoms_cpu, N_STEPS, N_PATHS)\n",
    "print('Multi-threaded CPU runtime:', time.time() - t0)\n",
    "\n",
    "exp_payoff = output.mean()\n",
    "print('Simulated expected payoff:', exp_payoff)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GPU with Numba\n",
    "It's also easy to parallelize the calculations to GPU via Numba using the `Numba.cuda.jit` decorator. The code below is very similar to the CPU multiple core code except that we parallelize the outer loop on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU run. Notice the `@cuda.jit` decorator, which is imported from Numba.\n",
    "@cuda.jit\n",
    "def numba_gpu_barrier_option(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS):\n",
    "    # Here, ii is the overall thread index. Note how they're used later in the for-loop.\n",
    "    ii = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
    "    stride = cuda.gridDim.x * cuda.blockDim.x\n",
    "\n",
    "    tmp1 = mu*T/N_STEPS\n",
    "    tmp2 = math.exp(-r*T)\n",
    "    tmp3 = math.sqrt(T/N_STEPS)\n",
    "\n",
    "    for i in range(ii, N_PATHS, stride):\n",
    "        s_curr = S0\n",
    "        running_average = 0.0\n",
    "        for n in range(N_STEPS):\n",
    "            s_curr += tmp1 * s_curr + sigma*s_curr*tmp3*d_normals[i + n * N_PATHS]\n",
    "            running_average += (s_curr - running_average) / (n + 1.0)\n",
    "            if running_average <= B:\n",
    "                break\n",
    "\n",
    "        payoff = running_average - K if running_average>K else 0\n",
    "        d_s[i] = tmp2 * payoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU runtime: 0.6308526992797852\n",
      "Simulated expected payoff: 18.70347\n"
     ]
    }
   ],
   "source": [
    "# GPU run:\n",
    "number_of_threads = 256\n",
    "number_of_blocks = (N_PATHS-1) // number_of_threads + 1\n",
    "output = cupy.zeros(N_PATHS, dtype=cupy.float32)\n",
    "\n",
    "t0 = time.time()\n",
    "numba_gpu_barrier_option[(number_of_blocks,), (number_of_threads,)](output, np.float32(T), np.float32(K), \n",
    "                    np.float32(B), np.float32(S0), \n",
    "                    np.float32(sigma), np.float32(mu), \n",
    "                    np.float32(r), randoms_gpu, N_STEPS, N_PATHS)\n",
    "cuda.synchronize()\n",
    "print('GPU runtime:', time.time() - t0)\n",
    "\n",
    "exp_payoff = output.mean()\n",
    "print('Simulated expected payoff:', exp_payoff)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clear memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del randoms_gpu\n",
    "del randoms_cpu\n",
    "del output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
